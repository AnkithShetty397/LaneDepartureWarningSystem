{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QWlc7QnHbcLV"},"outputs":[],"source":["!pip install segmentation_models_pytorch"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6970,"status":"ok","timestamp":1706581021361,"user":{"displayName":"ANKITH SHETTY","userId":"07871395509822048618"},"user_tz":-330},"id":"59psHpl8cIVj"},"outputs":[],"source":["from torchvision.transforms import transforms\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import os\n","\n","class CustomDataset1(Dataset):\n","    def __init__(self, data_folder, input_size=(960,640)):\n","        self.input_size = input_size\n","        self.image_dir = data_folder\n","        self.images = [file for file in os.listdir(self.image_dir) if file.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","        self.transform_image = transforms.Compose([\n","            transforms.Resize(self.input_size),\n","        ])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.image_dir, self.images[idx])\n","        image = Image.open(img_path)\n","        image = self.transform_image(image)\n","        return image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":40498,"status":"ok","timestamp":1706581545906,"user":{"displayName":"ANKITH SHETTY","userId":"07871395509822048618"},"user_tz":-330},"id":"tVjD-VhpdBoi","outputId":"808cc607-27ba-472d-da81-ef09782c8dc5"},"outputs":[],"source":["import segmentation_models_pytorch as smp\n","import torch\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import timeit\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","encoder = 'resnet18'\n","\n","model = smp.Unet(encoder, in_channels=3, classes=1, activation=None).to(device)\n","\n","checkpoint_path = \"/model/unet_resnet18_100k.pth\"\n","checkpoint = torch.load(checkpoint_path, map_location=device)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","\n","model.eval()\n","\n","image_path = \"/data/demo/\"\n","dataset = CustomDataset1(image_path)\n","input_size = (640, 960)\n","\n","x0, x1, x2, x3 = 380,960-380,960-300,300\n","y0, y1 = 520, 640\n","\n","y, x = np.ogrid[:640, :960]\n","\n","condition = (x >= x0 + (x3 - x0) / (y1 - y0) * (y - y0)) & (x < x1 + (x2 - x1) / (y1 - y0) * (y - y0)) & (y >= y0) & (y < y1)\n","\n","transform = transforms.Compose([\n","        transforms.ToTensor()\n","    ])\n","\n","for input_image in dataset:\n","    start_time = timeit.default_timer()\n","    input_tensor = transform(input_image).to(device)\n","    input_batch = input_tensor.unsqueeze(0)\n","    with torch.no_grad():\n","        output = model(input_batch)\n","\n","    output_image = output.squeeze().detach().cpu().numpy()\n","    output_image = ((output_image - output_image.min()) / (output_image.max() - output_image.min()))\n","    output_image[output_image>0.83]=255\n","\n","    mask = np.zeros((640, 960), dtype=np.uint8)\n","    mask = torch.zeros((1, 640, 960), dtype=torch.uint8).to(device)\n","\n","    mask[0, condition] = 1\n","    res = output_image * mask.cpu().numpy()\n","    sum_value = np.sum(res)\n","\n","    if sum_value < 25500:\n","        input_image=input_image.resize((960,640))\n","        original_image_np = np.array(input_image)\n","        green_mask = np.zeros_like(original_image_np)\n","        green_mask[:, :, 1] = 255\n","        green_mask_resized = cv2.resize(green_mask, (960, 640))\n","        overlay = original_image_np.copy()\n","        boolean_mask_np = mask.cpu().numpy()[0, ...].astype(bool)\n","        overlay[boolean_mask_np] = cv2.addWeighted(\n","            original_image_np[boolean_mask_np], 1,\n","            green_mask_resized[boolean_mask_np], 0.5, 0\n","        )\n","    else:\n","        input_image=input_image.resize((960,640))\n","        original_image_np = np.array(input_image)\n","        red_mask = np.zeros_like(original_image_np)\n","        red_mask[:, :, 0] = 255\n","        red_mask_resized = cv2.resize(red_mask, (960, 640))\n","        overlay = original_image_np.copy()\n","        boolean_mask_np = mask.cpu().numpy()[0, ...].astype(bool)\n","        overlay[boolean_mask_np] = cv2.addWeighted(\n","            original_image_np[boolean_mask_np], 1,\n","            red_mask_resized[boolean_mask_np], 0.5, 0\n","        )\n","\n","    end_time = timeit.default_timer()\n","    elapsed_time = end_time - start_time\n","    print(f\"Elapsed time: {elapsed_time} seconds\")\n","\n","    plt.figure(figsize=(10, 5))\n","\n","    plt.subplot(1, 3, 1)\n","    plt.title('Original Image')\n","    plt.imshow(input_image)\n","\n","    plt.subplot(1, 3, 2)\n","    plt.title('Output Image')\n","    plt.imshow(overlay)\n","\n","    plt.subplot(1, 3, 3)\n","    plt.title('Model Output')\n","    plt.imshow(output_image, cmap='gray')\n","\n","    plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOxj1TMuOXJ6eoFI7RZEXes","mount_file_id":"1mBMUp7yYwgUc9UBML4DoUwtpXSpQP3vR","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
