{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wmqUjYGom5j_"},"outputs":[],"source":["!pip install segmentation_models_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhbwxwQOm7aS"},"outputs":[],"source":["from torchvision.transforms import transforms\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import os\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, data_folder, mask_path, input_size=(960,640), mask_size=(960,640)):\n","        self.input_size = input_size\n","        self.image_dir = data_folder\n","        self.mask_size = mask_size\n","        self.mask_path = mask_path\n","        self.images = os.listdir(self.image_dir)\n","\n","        self.transform_image = transforms.Compose([\n","            transforms.Resize(self.input_size),\n","            transforms.ToTensor(),\n","        ])\n","\n","        self.transform_mask = transforms.Compose([\n","            transforms.Resize(self.mask_size),\n","            transforms.Grayscale(num_output_channels=1),\n","            transforms.ToTensor(),\n","        ])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.image_dir, self.images[idx])\n","        mask_path = os.path.join(self.mask_path, self.images[idx].replace(\".jpg\", \".png\"))\n","        image = Image.open(img_path)\n","        mask = Image.open(mask_path)\n","\n","        image = self.transform_image(image)\n","        mask = self.transform_mask(mask)\n","\n","        return image, mask\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2WsfZ1xm58c","outputId":"8688b5c5-f975-4d61-9142-7a8a4da6510b"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm\n","import segmentation_models_pytorch as smp\n","import os\n","import glob\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Hyperparameters\n","num_classes = 1\n","batch_size = 16\n","learning_rate = 0.0001\n","num_epochs = 20\n","\n","model_name = 'unet'\n","encoder_name = 'resnet18'\n","\n","model = smp.Unet(encoder_name, in_channels=3, classes=num_classes, activation=\"sigmoid\").to(device)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","model = model.to(device)\n","\n","train_image_path = \"/data/training/images\"\n","train_mask_path = \"/data/training/masks\"\n","\n","train_dataset = CustomDataset(train_image_path, train_mask_path)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","checkpoint_dir = '/model/checkpoints/'\n","latest_checkpoint = max(glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pth')), key=os.path.getctime, default=None)\n","\n","if latest_checkpoint is not None:\n","    checkpoint = torch.load(latest_checkpoint)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    start_epoch = checkpoint['epoch']\n","    print(f\"Resuming training from epoch {start_epoch}, loss: {checkpoint['loss']:.4f}\")\n","else:\n","    start_epoch = 0\n","    print(\"No checkpoint found. Starting from epoch 0.\")\n","\n","for epoch in range(start_epoch, num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    with tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} (Training)', leave=True) as train_bar:\n","        for batch_idx, (images, masks) in enumerate(train_bar):\n","            images, masks = images.to(device), masks.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, masks)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            train_bar.set_postfix(loss=f'{loss.item():.4f}')\n","\n","    average_loss = running_loss / len(train_loader)\n","\n","    save_interval = 1\n","    if (epoch + 1) % save_interval == 0:\n","        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + 1}.pth')\n","        torch.save({\n","            'epoch': epoch + 1,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': average_loss,\n","        }, checkpoint_path)\n","\n","        print(f\"Checkpoint saved at {checkpoint_path}\")\n","    torch.save(model.state_dict(), '/model/unet_resnet18_100k.pth')\n","\n","torch.save(model.state_dict(), '/model/unet_resnet18_100k.pth')\n","torch.cuda.empty_cache()\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOR6COStM8N3xFRdAM+iWzs","gpuType":"T4","mount_file_id":"1-8wMeOH98A41sNda1jWqDP-VyObKfxeT","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
